{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libary"
      ],
      "metadata": {
        "id": "BE1Gt7OfBiM4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_2PtuFbiEsL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "066rWDrlBlr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1e45f1GmiKKtHkbZPg8WkyjemBVWgjfOE\"\n",
        "\n",
        "# URL berbagi dari Google Drive\n",
        "url = 'https://drive.google.com/uc?id=' + file_id\n",
        "\n",
        "# Path untuk menyimpan file yang diunduh\n",
        "output = 'dataset.zip'\n",
        "\n",
        "# Mengunduh file\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Mengekstrak file zip jika diperlukan\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall('datasets/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gobl414ekjz8",
        "outputId": "f180b2b1-9c4f-4912-b6c1-829e4594ee98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1e45f1GmiKKtHkbZPg8WkyjemBVWgjfOE\n",
            "From (redirected): https://drive.google.com/uc?id=1e45f1GmiKKtHkbZPg8WkyjemBVWgjfOE&confirm=t&uuid=9e1cd2b9-90db-4017-bb12-e92912455ed7\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 653M/653M [00:35<00:00, 18.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "dlZl76MQ-V_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Clean Dataset"
      ],
      "metadata": {
        "id": "mDD5bqhi9hfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_and_remove_invalid_images(root_dir):\n",
        "    invalid_files = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # Attempt to open and verify the image\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image: {file_path} - {e}\")\n",
        "                invalid_files.append(file_path)\n",
        "    # Remove invalid files\n",
        "    for invalid_file in invalid_files:\n",
        "        os.remove(invalid_file)\n",
        "        print(f\"Invalid image removed: {invalid_file}\")"
      ],
      "metadata": {
        "id": "WB3o5rJJ9f80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_paths_and_labels(root_dir):\n",
        "    # Check and remove invalid images before collecting file paths and labels\n",
        "    check_and_remove_invalid_images(root_dir)\n",
        "\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            label = os.path.basename(subdir)\n",
        "            file_paths.append(file_path)\n",
        "            labels.append(label)\n",
        "    return file_paths, labels"
      ],
      "metadata": {
        "id": "jxCMyqc_mOlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Direktori asal, train, dan validation\n",
        "root_dir = '/content/datasets/'\n",
        "train_dir = '/content/final-datasets/train'\n",
        "val_dir = '/content/final-datasets/valid'\n",
        "\n",
        "# Membuat direktori train dan validation jika belum ada\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Mendapatkan semua jalur file dan labelnya\n",
        "file_paths, labels = get_file_paths_and_labels(root_dir)"
      ],
      "metadata": {
        "id": "7_y3IZjSmREC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d68695e-38ee-4447-99c6-231fc3f6216e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing image: /content/datasets/daun kemangi/daun-kemangi_154.jpg - cannot identify image file '/content/datasets/daun kemangi/daun-kemangi_154.jpg'\n",
            "Error processing image: /content/datasets/daun kemangi/daun-kemangi_160.jpg - cannot identify image file '/content/datasets/daun kemangi/daun-kemangi_160.jpg'\n",
            "Error processing image: /content/datasets/daun kemangi/daun-kemangi_180.jpg - cannot identify image file '/content/datasets/daun kemangi/daun-kemangi_180.jpg'\n",
            "Error processing image: /content/datasets/bawang putih/bawang-putih_152.jpg - cannot identify image file '/content/datasets/bawang putih/bawang-putih_152.jpg'\n",
            "Invalid image removed: /content/datasets/daun kemangi/daun-kemangi_154.jpg\n",
            "Invalid image removed: /content/datasets/daun kemangi/daun-kemangi_160.jpg\n",
            "Invalid image removed: /content/datasets/daun kemangi/daun-kemangi_180.jpg\n",
            "Invalid image removed: /content/datasets/bawang putih/bawang-putih_152.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset"
      ],
      "metadata": {
        "id": "xcaT8pQV92s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_move_files(file_paths, labels, train_dir, val_dir, test_size=0.2):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(file_paths, labels, test_size=test_size, stratify=labels, random_state=234)\n",
        "\n",
        "    for file_path, label in zip(X_train, y_train):\n",
        "        label_dir = os.path.join(train_dir, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        shutil.copy(file_path, label_dir)\n",
        "\n",
        "    for file_path, label in zip(X_val, y_val):\n",
        "        label_dir = os.path.join(val_dir, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        shutil.copy(file_path, label_dir)"
      ],
      "metadata": {
        "id": "U3bL_r-x-Cqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dan memindahkan file ke direktori train dan validation\n",
        "split_and_move_files(\n",
        "    file_paths,\n",
        "    labels,\n",
        "    train_dir,\n",
        "    val_dir,\n",
        "    test_size=0.2\n",
        "    )"
      ],
      "metadata": {
        "id": "q7_nRT5v9-Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generator and Augmentation"
      ],
      "metadata": {
        "id": "4zXAtkvf9EXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator untuk training dan validation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Membuat generator untuk training dan validation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4QTDVnw803t",
        "outputId": "2c04f648-b744-4bbb-d11d-a39edd851157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5049 images belonging to 31 classes.\n",
            "Found 1263 images belonging to 31 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "4jZDbRE9Bsx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading VGG16 model\n",
        "vgg16_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3))\n",
        "vgg16_model.trainable= False\n",
        "vgg16_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2xbC8ATUftE",
        "outputId": "336d70b5-66be-41b2-c8c2-88e7a89916b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    vgg16_model,\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(31, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = 'rmsprop'\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=20,\n",
        "    batch_size = 32,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "id": "JsyPvY5rmTH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6a1c03-67e8-463f-bde2-f27182584dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 - 125s - loss: 3.6964 - accuracy: 0.0396 - val_loss: 3.4334 - val_accuracy: 0.0443 - 125s/epoch - 792ms/step\n",
            "Epoch 2/20\n",
            "158/158 - 113s - loss: 3.3543 - accuracy: 0.0709 - val_loss: 2.8618 - val_accuracy: 0.1726 - 113s/epoch - 718ms/step\n",
            "Epoch 3/20\n",
            "158/158 - 114s - loss: 2.5295 - accuracy: 0.2490 - val_loss: 1.9399 - val_accuracy: 0.4133 - 114s/epoch - 724ms/step\n",
            "Epoch 4/20\n",
            "158/158 - 115s - loss: 2.0340 - accuracy: 0.3795 - val_loss: 1.5713 - val_accuracy: 0.5146 - 115s/epoch - 729ms/step\n",
            "Epoch 5/20\n",
            "158/158 - 115s - loss: 1.8046 - accuracy: 0.4413 - val_loss: 1.3735 - val_accuracy: 0.5891 - 115s/epoch - 727ms/step\n",
            "Epoch 6/20\n",
            "158/158 - 115s - loss: 1.6490 - accuracy: 0.4862 - val_loss: 1.2086 - val_accuracy: 0.6334 - 115s/epoch - 729ms/step\n",
            "Epoch 7/20\n",
            "158/158 - 112s - loss: 1.5362 - accuracy: 0.5270 - val_loss: 1.0792 - val_accuracy: 0.6785 - 112s/epoch - 706ms/step\n",
            "Epoch 8/20\n",
            "158/158 - 114s - loss: 1.5095 - accuracy: 0.5302 - val_loss: 1.0730 - val_accuracy: 0.6619 - 114s/epoch - 722ms/step\n",
            "Epoch 9/20\n",
            "158/158 - 113s - loss: 1.4139 - accuracy: 0.5575 - val_loss: 1.1089 - val_accuracy: 0.6635 - 113s/epoch - 716ms/step\n",
            "Epoch 10/20\n",
            "158/158 - 113s - loss: 1.3705 - accuracy: 0.5702 - val_loss: 1.0527 - val_accuracy: 0.6659 - 113s/epoch - 718ms/step\n",
            "Epoch 11/20\n",
            "158/158 - 114s - loss: 1.3418 - accuracy: 0.5861 - val_loss: 1.1648 - val_accuracy: 0.6382 - 114s/epoch - 721ms/step\n",
            "Epoch 12/20\n",
            "158/158 - 115s - loss: 1.2778 - accuracy: 0.6033 - val_loss: 0.9474 - val_accuracy: 0.7126 - 115s/epoch - 726ms/step\n",
            "Epoch 13/20\n",
            "158/158 - 112s - loss: 1.2853 - accuracy: 0.6029 - val_loss: 0.9264 - val_accuracy: 0.7102 - 112s/epoch - 710ms/step\n",
            "Epoch 14/20\n",
            "158/158 - 116s - loss: 1.1840 - accuracy: 0.6237 - val_loss: 1.0219 - val_accuracy: 0.6936 - 116s/epoch - 732ms/step\n",
            "Epoch 15/20\n",
            "158/158 - 111s - loss: 1.2067 - accuracy: 0.6263 - val_loss: 0.8686 - val_accuracy: 0.7292 - 111s/epoch - 705ms/step\n",
            "Epoch 16/20\n",
            "158/158 - 114s - loss: 1.1847 - accuracy: 0.6360 - val_loss: 0.9148 - val_accuracy: 0.7245 - 114s/epoch - 722ms/step\n",
            "Epoch 17/20\n",
            "158/158 - 115s - loss: 1.1539 - accuracy: 0.6407 - val_loss: 0.8471 - val_accuracy: 0.7561 - 115s/epoch - 729ms/step\n",
            "Epoch 18/20\n",
            "158/158 - 120s - loss: 1.1346 - accuracy: 0.6508 - val_loss: 0.8556 - val_accuracy: 0.7411 - 120s/epoch - 758ms/step\n",
            "Epoch 19/20\n",
            "158/158 - 123s - loss: 1.1347 - accuracy: 0.6518 - val_loss: 0.7809 - val_accuracy: 0.7743 - 123s/epoch - 778ms/step\n",
            "Epoch 20/20\n",
            "158/158 - 119s - loss: 1.0957 - accuracy: 0.6661 - val_loss: 0.7630 - val_accuracy: 0.7712 - 119s/epoch - 756ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e020e73a260>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}