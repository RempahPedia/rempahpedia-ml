{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libary"
      ],
      "metadata": {
        "id": "BE1Gt7OfBiM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tucbI68RCb7a",
        "outputId": "75d7e2b1-b059-480e-99dc-c1f8bb73f1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez33lKsNCfvu",
        "outputId": "25f81978-ebc6-45bf-91e2-1e60a294a8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOUyh94uBx04",
        "outputId": "f95aa75b-a541-4427-d03a-cd0fe2d21def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_2PtuFbiEsL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "066rWDrlBlr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = \"1e45f1GmiKKtHkbZPg8WkyjemBVWgjfOE\"\n",
        "\n",
        "# URL berbagi dari Google Drive\n",
        "url = 'https://drive.google.com/uc?id=' + file_id\n",
        "\n",
        "# Path untuk menyimpan file yang diunduh\n",
        "output = 'dataset.zip'\n",
        "\n",
        "# Mengunduh file\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# Mengekstrak file zip jika diperlukan\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall('datasets/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gobl414ekjz8",
        "outputId": "d831c07c-bcd0-4252-9858-d544e7af4bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1e45f1GmiKKtHkbZPg8WkyjemBVWgjfOE\n",
            "From (redirected): https://drive.google.com/uc?id=1e45f1GmiKKtHkbZPg8WkyjemBVWgjfOE&confirm=t&uuid=f213586b-41cb-4ae3-8ae2-dd56d1ab5396\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 653M/653M [00:22<00:00, 29.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_and_remove_invalid_images(root_dir):\n",
        "    invalid_files = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()  # Attempt to open and verify the image\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image: {file_path} - {e}\")\n",
        "                invalid_files.append(file_path)\n",
        "    # Remove invalid files\n",
        "    for invalid_file in invalid_files:\n",
        "        os.remove(invalid_file)\n",
        "        print(f\"Invalid image removed: {invalid_file}\")\n",
        "\n",
        "def get_file_paths_and_labels(root_dir):\n",
        "    # Check and remove invalid images before collecting file paths and labels\n",
        "    check_and_remove_invalid_images(root_dir)\n",
        "\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            label = os.path.basename(subdir)\n",
        "            file_paths.append(file_path)\n",
        "            labels.append(label)\n",
        "    return file_paths, labels"
      ],
      "metadata": {
        "id": "jxCMyqc_mOlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_move_files(file_paths, labels, train_dir, val_dir, test_size=0.2):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(file_paths, labels, test_size=test_size, stratify=labels, random_state=234)\n",
        "\n",
        "    for file_path, label in zip(X_train, y_train):\n",
        "        label_dir = os.path.join(train_dir, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        shutil.copy(file_path, label_dir)\n",
        "\n",
        "    for file_path, label in zip(X_val, y_val):\n",
        "        label_dir = os.path.join(val_dir, label)\n",
        "        os.makedirs(label_dir, exist_ok=True)\n",
        "        shutil.copy(file_path, label_dir)"
      ],
      "metadata": {
        "id": "Y8eVmlMRmPJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Direktori asal, train, dan validation\n",
        "root_dir = '/content/datasets/'\n",
        "train_dir = '/content/final-datasets/train'\n",
        "val_dir = '/content/final-datasets/valid'\n",
        "\n",
        "# Membuat direktori train dan validation jika belum ada\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Mendapatkan semua jalur file dan labelnya\n",
        "file_paths, labels = get_file_paths_and_labels(root_dir)\n",
        "\n",
        "# Membagi dan memindahkan file ke direktori train dan validation\n",
        "split_and_move_files(\n",
        "    file_paths,\n",
        "    labels,\n",
        "    train_dir,\n",
        "    val_dir,\n",
        "    test_size=0.2\n",
        "    )"
      ],
      "metadata": {
        "id": "7_y3IZjSmREC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66269ef6-07be-4f17-cab0-4f302902d1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing image: /content/datasets/daun kemangi/daun-kemangi_160.jpg - cannot identify image file '/content/datasets/daun kemangi/daun-kemangi_160.jpg'\n",
            "Error processing image: /content/datasets/daun kemangi/daun-kemangi_180.jpg - cannot identify image file '/content/datasets/daun kemangi/daun-kemangi_180.jpg'\n",
            "Error processing image: /content/datasets/daun kemangi/daun-kemangi_154.jpg - cannot identify image file '/content/datasets/daun kemangi/daun-kemangi_154.jpg'\n",
            "Error processing image: /content/datasets/bawang putih/bawang-putih_152.jpg - cannot identify image file '/content/datasets/bawang putih/bawang-putih_152.jpg'\n",
            "Invalid image removed: /content/datasets/daun kemangi/daun-kemangi_160.jpg\n",
            "Invalid image removed: /content/datasets/daun kemangi/daun-kemangi_180.jpg\n",
            "Invalid image removed: /content/datasets/daun kemangi/daun-kemangi_154.jpg\n",
            "Invalid image removed: /content/datasets/bawang putih/bawang-putih_152.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "4jZDbRE9Bsx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageDataGenerator untuk training dan validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Membuat generator untuk training dan validation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(31, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=10,\n",
        "    batch_size = 32,\n",
        ")"
      ],
      "metadata": {
        "id": "JsyPvY5rmTH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f68414-febb-4d19-f51f-9927640fa3f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5049 images belonging to 31 classes.\n",
            "Found 1263 images belonging to 31 classes.\n",
            "Epoch 1/10\n",
            " 44/158 [=======>......................] - ETA: 4:21 - loss: 3.4790 - accuracy: 0.0857"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 384s 2s/step - loss: 3.1691 - accuracy: 0.1173 - val_loss: 2.7511 - val_accuracy: 0.1956\n",
            "Epoch 2/10\n",
            "158/158 [==============================] - 397s 3s/step - loss: 2.5467 - accuracy: 0.2551 - val_loss: 2.4031 - val_accuracy: 0.2581\n",
            "Epoch 3/10\n",
            "158/158 [==============================] - 403s 3s/step - loss: 2.2347 - accuracy: 0.3393 - val_loss: 2.1613 - val_accuracy: 0.3508\n",
            "Epoch 4/10\n",
            "158/158 [==============================] - 385s 2s/step - loss: 1.9414 - accuracy: 0.4328 - val_loss: 2.0772 - val_accuracy: 0.3674\n",
            "Epoch 5/10\n",
            "158/158 [==============================] - 406s 3s/step - loss: 1.6044 - accuracy: 0.5361 - val_loss: 1.8595 - val_accuracy: 0.4418\n",
            "Epoch 6/10\n",
            "158/158 [==============================] - 407s 3s/step - loss: 1.2892 - accuracy: 0.6304 - val_loss: 1.8547 - val_accuracy: 0.4291\n",
            "Epoch 7/10\n",
            "158/158 [==============================] - 385s 2s/step - loss: 0.9828 - accuracy: 0.7304 - val_loss: 1.6874 - val_accuracy: 0.5107\n",
            "Epoch 8/10\n",
            "158/158 [==============================] - 400s 3s/step - loss: 0.7224 - accuracy: 0.8069 - val_loss: 1.6970 - val_accuracy: 0.5036\n",
            "Epoch 9/10\n",
            "158/158 [==============================] - 410s 3s/step - loss: 0.4935 - accuracy: 0.8758 - val_loss: 1.6428 - val_accuracy: 0.5424\n",
            "Epoch 10/10\n",
            "158/158 [==============================] - 388s 2s/step - loss: 0.3173 - accuracy: 0.9305 - val_loss: 1.7431 - val_accuracy: 0.5131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a8af031cbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}